{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB_Sentiment_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNw4FgdARMct3fsgDk0XGLc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArshT/Pytorch_Practice/blob/master/IMDB_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-lEaCOM3sL1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as Optim\n",
        "from torchtext.legacy import data"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zazqqmub6Igq"
      },
      "source": [
        "TEXT = data.Field(tokenize='spacy',tokenizer_language='en_core_web_sm',include_lengths=True)\n",
        "LABEL = data.LabelField(dtype=torch.float)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO3yj-K17LEj"
      },
      "source": [
        "from torchtext.legacy import datasets\n",
        "\n",
        "train_data,test_data = datasets.IMDB.splits(TEXT,LABEL)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oarl_JlE8_3e"
      },
      "source": [
        "train_data,val_data = train_data.split()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQI16lQ09fFr"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "\n",
        "TEXT.build_vocab(train_data,max_size = MAX_VOCAB_SIZE,vectors = 'glove.6B.100d',unk_init = torch.Tensor.normal_)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3BWdJbd9xHV"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda')\n",
        "\n",
        "train_iterator,val_iterator,test_iterator = data.BucketIterator.splits((train_data,val_data,test_data),\n",
        "                                                                        batch_size=BATCH_SIZE,\n",
        "                                                                        sort_within_batch=True,\n",
        "                                                                        device=device)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WgEvln9_k-_"
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self,vocab_size,embedding_dim,hidden_dim,output_dim,n_layers,bidirectional,dropout,pad_idx):\n",
        "    super(Net,self).__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size,embedding_dim,padding_idx=pad_idx)\n",
        "\n",
        "    self.lstm_layer = nn.LSTM(embedding_dim,hidden_dim,num_layers=n_layers,bidirectional=bidirectional,dropout=dropout)\n",
        "\n",
        "    self.fc = nn.Linear(hidden_dim*2,output_dim)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "\n",
        "  def forward(self,text,text_lengths):\n",
        "\n",
        "    embedded =  self.dropout(self.embedding(text))\n",
        "\n",
        "    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded,text_lengths.to('cpu'))\n",
        "\n",
        "    packet_output,(hidden,cell) = self.lstm_layer(packed_embedded)\n",
        "\n",
        "    hidden = self.dropout(torch.cat((hidden[-2,:,:],hidden[-1,:,:]),dim=1))\n",
        "\n",
        "    output = self.fc(hidden)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JewhzDNCvDB",
        "outputId": "4c05594b-5684-44d8-8915-0d2de3c25523"
      },
      "source": [
        "VOCAB_SIZE = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "net = Net(VOCAB_SIZE,\n",
        "          EMBEDDING_DIM,\n",
        "          HIDDEN_DIM,\n",
        "          OUTPUT_DIM,\n",
        "          N_LAYERS,\n",
        "          BIDIRECTIONAL,\n",
        "          DROPOUT,\n",
        "          PAD_IDX\n",
        "          )\n",
        "net.to(device)\n",
        "\n",
        "print(net)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
            "  (lstm_layer): LSTM(100, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
            "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jcBqgFPD2EO",
        "outputId": "6e90310b-deae-4cf0-e7e7-11324e10951d"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "net.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.9850,  0.7400,  2.6182,  ..., -0.6623, -1.2012,  1.1092],\n",
              "        [-1.1947, -0.6932, -0.3686,  ...,  1.3607, -0.4500,  0.6598],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [ 0.7221,  0.7693, -0.2417,  ..., -1.1507,  1.2279, -0.2337],\n",
              "        [-1.7035,  1.4701,  0.6830,  ...,  0.4607, -0.1707, -1.2048],\n",
              "        [-0.2834, -1.5427, -0.0986,  ...,  1.0882,  0.1482,  0.1804]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETs-xfBfFBws",
        "outputId": "3424b830-fe84-4129-de40-01d6ebd3da6f"
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "net.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "net.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(net.embedding.weight.data)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [ 0.7221,  0.7693, -0.2417,  ..., -1.1507,  1.2279, -0.2337],\n",
            "        [-1.7035,  1.4701,  0.6830,  ...,  0.4607, -0.1707, -1.2048],\n",
            "        [-0.2834, -1.5427, -0.0986,  ...,  1.0882,  0.1482,  0.1804]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug535tHFFOtM"
      },
      "source": [
        "optimizer = Optim.Adam(net.parameters())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK-Ylvb4F8-U",
        "outputId": "087db1f7-74df-4dbe-9383-21521ffe3df8"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "criterion.to(device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCEWithLogitsLoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6jc565MGCej"
      },
      "source": [
        "def binary_accuracy(model,iterator,criterion):\n",
        "  \n",
        "  EPOCH_loss = 0\n",
        "  EPOCH_acc = 0\n",
        "\n",
        "  for batch in iterator:\n",
        "    model.eval()\n",
        "\n",
        "    text,text_lengths = batch.text\n",
        "    labels = batch.label\n",
        "    labels = labels.reshape(labels.shape[0],1)\n",
        "\n",
        "    pred = model(text,text_lengths)\n",
        "\n",
        "    rounded_preds = torch.round(torch.sigmoid(pred))\n",
        "    correct = (rounded_preds == labels).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "\n",
        "    loss = criterion(pred,labels)\n",
        "\n",
        "    EPOCH_loss += loss.item()\n",
        "    EPOCH_acc  += acc.item()\n",
        "  \n",
        "  return EPOCH_loss / len(iterator), EPOCH_acc / len(iterator)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LY-Z-HW9H-pn",
        "outputId": "f5c1347f-d1bf-4ca0-9c44-b4f06182d0c9"
      },
      "source": [
        "n_epochs = 10\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  train_epoch_loss = 0\n",
        "  train_epoch_acc = 0\n",
        "\n",
        "  for batch in train_iterator:\n",
        "    net.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    text,text_lengths = batch.text\n",
        "    labels = batch.label\n",
        "    labels = labels.reshape(labels.shape[0],1)\n",
        "\n",
        "    predictions = net(text,text_lengths)\n",
        "    loss = criterion(predictions,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_epoch_loss += loss.item()\n",
        "\n",
        "    rounded_preds = torch.round(torch.sigmoid(predictions))\n",
        "    correct = (rounded_preds == labels).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "\n",
        "    train_epoch_acc  += acc.item()\n",
        "  \n",
        "  train_epoch_acc /= len(train_iterator)\n",
        "  train_epoch_loss /= len(train_iterator)\n",
        "\n",
        "  val_loss,val_acc = binary_accuracy(net,val_iterator,criterion)\n",
        "  print(\"Epoch:\",epoch+1)\n",
        "  print(\"train:\",train_epoch_loss,train_epoch_acc)\n",
        "  print(\"val:\",val_loss,val_acc)\n",
        "  print()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "train: 0.6314426115612044 0.6316475496239906\n",
            "val: 0.50266882524652 0.768802966101695\n",
            "\n",
            "Epoch: 2\n",
            "train: 0.5303703298533919 0.7347578858807139\n",
            "val: 0.3983468602774507 0.8289194915254238\n",
            "\n",
            "Epoch: 3\n",
            "train: 0.40500562458577816 0.8257706596033416\n",
            "val: 0.3528545486219859 0.8560646186440678\n",
            "\n",
            "Epoch: 4\n",
            "train: 0.34612352993801565 0.8510003912187841\n",
            "val: 0.31819902246786375 0.8674523305084746\n",
            "\n",
            "Epoch: 5\n",
            "train: 0.3026000563680691 0.8751547836909329\n",
            "val: 0.2966156202857777 0.8866525423728814\n",
            "\n",
            "Epoch: 6\n",
            "train: 0.2839069991868778 0.8836597369535126\n",
            "val: 0.312440714341099 0.8907574152542372\n",
            "\n",
            "Epoch: 7\n",
            "train: 0.23174012202198488 0.9076756386861314\n",
            "val: 0.2713197186841803 0.8997616525423728\n",
            "\n",
            "Epoch: 8\n",
            "train: 0.20655348619622907 0.9207752216471373\n",
            "val: 0.2613512265606452 0.8989671610169492\n",
            "\n",
            "Epoch: 9\n",
            "train: 0.17923697375141792 0.9331334724913548\n",
            "val: 0.26635889027078274 0.8990112997717776\n",
            "\n",
            "Epoch: 10\n",
            "train: 0.16262604555890073 0.9380132299270073\n",
            "val: 0.3085264937983731 0.8987023305084746\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ6_ULXDQecI"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}