{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_Cifar-10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMkdjMSu1axktiPoR7Ed8v6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a139742354b348bf83f607f6d7bcb2f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_334867e6a3a543cf85ad2d39dc0aaad7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0148f6d9524c4b35b6391b59119a67e8",
              "IPY_MODEL_8fb9d504ea6d41e9833a8c2c0081626c"
            ]
          }
        },
        "334867e6a3a543cf85ad2d39dc0aaad7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0148f6d9524c4b35b6391b59119a67e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d6f6150a7c0b4a7eb5e8e9407d4fc6ec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6856b0081fe840959a7583f23082cf0d"
          }
        },
        "8fb9d504ea6d41e9833a8c2c0081626c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4e48befee59846ac9410e96e200b2e32",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:30&lt;00:00, 10671503.22it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e60df5fc01f748ce9ebbaafc1cf5ecba"
          }
        },
        "d6f6150a7c0b4a7eb5e8e9407d4fc6ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6856b0081fe840959a7583f23082cf0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e48befee59846ac9410e96e200b2e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e60df5fc01f748ce9ebbaafc1cf5ecba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArshT/Pytorch_Practice/blob/master/Pytorch_Cifar_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n73eJGKtrHBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxDK9upTuO5w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "a139742354b348bf83f607f6d7bcb2f6",
            "334867e6a3a543cf85ad2d39dc0aaad7",
            "0148f6d9524c4b35b6391b59119a67e8",
            "8fb9d504ea6d41e9833a8c2c0081626c",
            "d6f6150a7c0b4a7eb5e8e9407d4fc6ec",
            "6856b0081fe840959a7583f23082cf0d",
            "4e48befee59846ac9410e96e200b2e32",
            "e60df5fc01f748ce9ebbaafc1cf5ecba"
          ]
        },
        "outputId": "fabbeaf5-1f08-462c-e94f-5c016e74afcc"
      },
      "source": [
        "transform_train = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                      transforms.RandomRotation(degrees=(-30, 30)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "\n",
        "transform_test = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform_train)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset,batch_size = 32,shuffle=True,num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform_test)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset,batch_size = 4,shuffle=False,num_workers=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a139742354b348bf83f607f6d7bcb2f6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iqp11xYOu0br",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c2e10666-8f52-41a4-8ef7-5d0d015aa40d"
      },
      "source": [
        "USE_GPU = True\n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "    print('using device: cuda')\n",
        "else:\n",
        "    print('using device: cpu')\n",
        "\n",
        "device = torch.device(\"cuda:0\" if USE_GPU else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQQ6Ey7Au3we",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "86a833a0-25d7-41dd-9306-940b3d40bc80"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3,32,kernel_size=(3,3),padding=(1,1),stride=(1,1))\n",
        "    self.batch1 = nn.BatchNorm2d(32)\n",
        "    self.conv2 = nn.Conv2d(32,32,kernel_size=(3,3),padding=(1,1),stride=(1,1))\n",
        "    self.batch2 = nn.BatchNorm2d(32)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(32,64,kernel_size=(3,3),padding=(1,1),stride=(1,1))\n",
        "    self.batch3 = nn.BatchNorm2d(64)\n",
        "    self.conv4 = nn.Conv2d(64,64,kernel_size=(3,3),padding=(1,1),stride=(1,1))\n",
        "    self.batch4 = nn.BatchNorm2d(64)\n",
        "\n",
        "    self.conv5 = nn.Conv2d(64,128,kernel_size=(3,3),padding=(1,1),stride=(1,1))\n",
        "    self.batch5 = nn.BatchNorm2d(128)\n",
        "    self.conv6 = nn.Conv2d(128,128,kernel_size=(3,3),padding=(1,1),stride=(1,1))\n",
        "    self.batch6 = nn.BatchNorm2d(128)\n",
        "\n",
        "    self.conv7 = nn.Conv2d(128,256,kernel_size=(3,3),padding=(1,1),stride=(1,1))\n",
        "    self.batch7 = nn.BatchNorm2d(256)\n",
        "    self.conv8 = nn.Conv2d(256,256,kernel_size=(3,3),padding=(1,1),stride=(1,1))\n",
        "    self.batch8 = nn.BatchNorm2d(256)\n",
        "    self.conv9 = nn.Conv2d(256,256,kernel_size=(3,3),padding=(1,1),stride=(1,1))\n",
        "    self.batch9 = nn.BatchNorm2d(256)\n",
        "\n",
        "    self.conv10 = nn.Conv2d(256,512,kernel_size=(3,3),padding=(1,1),stride=(1,1))\n",
        "    self.batch10 = nn.BatchNorm2d(512)\n",
        "    self.conv11 = nn.Conv2d(512,512,kernel_size=(3,3),padding=(1,1),stride=(1,1))\n",
        "    self.batch11 = nn.BatchNorm2d(512)\n",
        "    self.conv12 = nn.Conv2d(512,512,kernel_size=(3,3),padding=(1,1),stride=(1,1))\n",
        "    self.batch12 = nn.BatchNorm2d(512)\n",
        "\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "\n",
        "    self.drop1 = nn.Dropout(0.2)\n",
        "    self.drop2 = nn.Dropout(0.3)\n",
        "    self.drop3 = nn.Dropout(0.4)\n",
        "    self.drop4 = nn.Dropout(0.5)\n",
        "    self.fc1 = nn.Linear(512*2*2,1024)\n",
        "    self.fc2 = nn.Linear(1024,512)\n",
        "    self.fc3 = nn.Linear(512,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.batch1(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.batch2(x)\n",
        "    x = self.drop1(x)\n",
        "\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = self.batch3(x)\n",
        "    x = F.relu(self.conv4(x))\n",
        "    x = self.batch4(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.drop2(x)\n",
        "\n",
        "    x = F.relu(self.conv5(x))\n",
        "    x = self.batch5(x)\n",
        "    x = F.relu(self.conv6(x))\n",
        "    x = self.batch6(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.drop2(x)\n",
        "\n",
        "    x = F.relu(self.conv7(x))\n",
        "    x = self.batch7(x)\n",
        "    x = F.relu(self.conv8(x))\n",
        "    x = self.batch8(x)\n",
        "    x = F.relu(self.conv9(x))\n",
        "    x = self.batch9(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.drop3(x)\n",
        "\n",
        "    x = F.relu(self.conv10(x))\n",
        "    x = self.batch10(x)\n",
        "    x = F.relu(self.conv11(x))\n",
        "    x = self.batch11(x)\n",
        "    x = F.relu(self.conv12(x))\n",
        "    x = self.batch12(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.drop3(x)\n",
        "\n",
        "\n",
        "    x = x.view(x.shape[0],512*2*2)\n",
        "\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.drop4(x)\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.drop4(x)\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "net = Net()\n",
        "net.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (batch1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (batch2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (batch3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (batch4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (batch5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (batch6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (batch7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (batch8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (batch9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv10): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (batch10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv11): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (batch11): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (batch12): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (drop1): Dropout(p=0.2, inplace=False)\n",
              "  (drop2): Dropout(p=0.3, inplace=False)\n",
              "  (drop3): Dropout(p=0.4, inplace=False)\n",
              "  (drop4): Dropout(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mC9xl6yyjn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001,momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhFYfyfBypnF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "30d4f7d3-6a67-4791-d5cd-3679f5a850cf"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "print(torch.cuda.device_count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5sgixcFyr97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_eval(dataloader):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for data in dataloader:\n",
        "      images, l = data\n",
        "      \n",
        "      images = images.to(device)\n",
        "      l = l.to(device)\n",
        "      \n",
        "      out = net(images)\n",
        "      max_val, preds = torch.max(out,dim=1)\n",
        "      \n",
        "      total += l.shape[0]                   \n",
        "      correct += (preds == l).sum().item()  \n",
        "      accuracy = (100 * correct)/total\n",
        "    \n",
        "    \n",
        "    return accuracy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-p7bTRmyvQR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5f49c9ae-9750-47bf-801e-d6ddb41ab8e1"
      },
      "source": [
        "\n",
        "for epoch in range(100):\n",
        "  print(\"Epoch:\",epoch+1)\n",
        "  running_loss = 0.0\n",
        "  for i,data in enumerate(trainloader,0):\n",
        "    inputs,labels = data\n",
        "    \n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    outputs = net(inputs)\n",
        "    outputs = outputs.to(device)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    \n",
        "    \n",
        "    if i % 300 == 299:    \n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 300))\n",
        "      running_loss = 0.0\n",
        "  \n",
        "  print(\"EPOCH OVER\")\n",
        "  train_acc = model_eval(trainloader)\n",
        "  test_acc = model_eval(testloader)\n",
        "  print(\"############################\")\n",
        "  print(\"Training Accuracy:\",train_acc,\"Testing Accuracy\",test_acc)\n",
        "  print(\"############################\")\n",
        "  print(\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "[1,   300] loss: 2.135\n",
            "[1,   600] loss: 1.843\n",
            "[1,   900] loss: 1.687\n",
            "[1,  1200] loss: 1.612\n",
            "[1,  1500] loss: 1.540\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 46.02 Testing Accuracy 40.12\n",
            "############################\n",
            "\n",
            "Epoch: 2\n",
            "[2,   300] loss: 1.456\n",
            "[2,   600] loss: 1.394\n",
            "[2,   900] loss: 1.385\n",
            "[2,  1200] loss: 1.329\n",
            "[2,  1500] loss: 1.297\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 54.58 Testing Accuracy 49.24\n",
            "############################\n",
            "\n",
            "Epoch: 3\n",
            "[3,   300] loss: 1.242\n",
            "[3,   600] loss: 1.229\n",
            "[3,   900] loss: 1.197\n",
            "[3,  1200] loss: 1.213\n",
            "[3,  1500] loss: 1.150\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 59.862 Testing Accuracy 54.2\n",
            "############################\n",
            "\n",
            "Epoch: 4\n",
            "[4,   300] loss: 1.128\n",
            "[4,   600] loss: 1.100\n",
            "[4,   900] loss: 1.081\n",
            "[4,  1200] loss: 1.066\n",
            "[4,  1500] loss: 1.061\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 64.018 Testing Accuracy 58.04\n",
            "############################\n",
            "\n",
            "Epoch: 5\n",
            "[5,   300] loss: 1.022\n",
            "[5,   600] loss: 0.998\n",
            "[5,   900] loss: 1.001\n",
            "[5,  1200] loss: 0.961\n",
            "[5,  1500] loss: 0.973\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 67.774 Testing Accuracy 61.8\n",
            "############################\n",
            "\n",
            "Epoch: 6\n",
            "[6,   300] loss: 0.928\n",
            "[6,   600] loss: 0.928\n",
            "[6,   900] loss: 0.921\n",
            "[6,  1200] loss: 0.928\n",
            "[6,  1500] loss: 0.905\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 69.354 Testing Accuracy 64.41\n",
            "############################\n",
            "\n",
            "Epoch: 7\n",
            "[7,   300] loss: 0.869\n",
            "[7,   600] loss: 0.873\n",
            "[7,   900] loss: 0.854\n",
            "[7,  1200] loss: 0.879\n",
            "[7,  1500] loss: 0.850\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 71.776 Testing Accuracy 66.06\n",
            "############################\n",
            "\n",
            "Epoch: 8\n",
            "[8,   300] loss: 0.826\n",
            "[8,   600] loss: 0.838\n",
            "[8,   900] loss: 0.813\n",
            "[8,  1200] loss: 0.816\n",
            "[8,  1500] loss: 0.821\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 72.756 Testing Accuracy 68.26\n",
            "############################\n",
            "\n",
            "Epoch: 9\n",
            "[9,   300] loss: 0.792\n",
            "[9,   600] loss: 0.793\n",
            "[9,   900] loss: 0.783\n",
            "[9,  1200] loss: 0.782\n",
            "[9,  1500] loss: 0.781\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 74.366 Testing Accuracy 69.3\n",
            "############################\n",
            "\n",
            "Epoch: 10\n",
            "[10,   300] loss: 0.725\n",
            "[10,   600] loss: 0.731\n",
            "[10,   900] loss: 0.774\n",
            "[10,  1200] loss: 0.748\n",
            "[10,  1500] loss: 0.745\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 75.586 Testing Accuracy 69.88\n",
            "############################\n",
            "\n",
            "Epoch: 11\n",
            "[11,   300] loss: 0.714\n",
            "[11,   600] loss: 0.693\n",
            "[11,   900] loss: 0.708\n",
            "[11,  1200] loss: 0.716\n",
            "[11,  1500] loss: 0.724\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 76.856 Testing Accuracy 71.28\n",
            "############################\n",
            "\n",
            "Epoch: 12\n",
            "[12,   300] loss: 0.700\n",
            "[12,   600] loss: 0.684\n",
            "[12,   900] loss: 0.697\n",
            "[12,  1200] loss: 0.683\n",
            "[12,  1500] loss: 0.664\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 77.908 Testing Accuracy 72.04\n",
            "############################\n",
            "\n",
            "Epoch: 13\n",
            "[13,   300] loss: 0.676\n",
            "[13,   600] loss: 0.653\n",
            "[13,   900] loss: 0.646\n",
            "[13,  1200] loss: 0.645\n",
            "[13,  1500] loss: 0.675\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 78.822 Testing Accuracy 73.43\n",
            "############################\n",
            "\n",
            "Epoch: 14\n",
            "[14,   300] loss: 0.647\n",
            "[14,   600] loss: 0.616\n",
            "[14,   900] loss: 0.638\n",
            "[14,  1200] loss: 0.636\n",
            "[14,  1500] loss: 0.632\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 79.502 Testing Accuracy 73.82\n",
            "############################\n",
            "\n",
            "Epoch: 15\n",
            "[15,   300] loss: 0.594\n",
            "[15,   600] loss: 0.626\n",
            "[15,   900] loss: 0.616\n",
            "[15,  1200] loss: 0.611\n",
            "[15,  1500] loss: 0.613\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 79.712 Testing Accuracy 74.03\n",
            "############################\n",
            "\n",
            "Epoch: 16\n",
            "[16,   300] loss: 0.590\n",
            "[16,   600] loss: 0.592\n",
            "[16,   900] loss: 0.591\n",
            "[16,  1200] loss: 0.610\n",
            "[16,  1500] loss: 0.610\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 80.722 Testing Accuracy 75.02\n",
            "############################\n",
            "\n",
            "Epoch: 17\n",
            "[17,   300] loss: 0.570\n",
            "[17,   600] loss: 0.565\n",
            "[17,   900] loss: 0.589\n",
            "[17,  1200] loss: 0.578\n",
            "[17,  1500] loss: 0.581\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 80.56 Testing Accuracy 74.9\n",
            "############################\n",
            "\n",
            "Epoch: 18\n",
            "[18,   300] loss: 0.565\n",
            "[18,   600] loss: 0.551\n",
            "[18,   900] loss: 0.574\n",
            "[18,  1200] loss: 0.554\n",
            "[18,  1500] loss: 0.568\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 81.382 Testing Accuracy 75.34\n",
            "############################\n",
            "\n",
            "Epoch: 19\n",
            "[19,   300] loss: 0.537\n",
            "[19,   600] loss: 0.530\n",
            "[19,   900] loss: 0.544\n",
            "[19,  1200] loss: 0.546\n",
            "[19,  1500] loss: 0.550\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 82.386 Testing Accuracy 75.94\n",
            "############################\n",
            "\n",
            "Epoch: 20\n",
            "[20,   300] loss: 0.509\n",
            "[20,   600] loss: 0.549\n",
            "[20,   900] loss: 0.535\n",
            "[20,  1200] loss: 0.531\n",
            "[20,  1500] loss: 0.514\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 82.04 Testing Accuracy 75.65\n",
            "############################\n",
            "\n",
            "Epoch: 21\n",
            "[21,   300] loss: 0.513\n",
            "[21,   600] loss: 0.500\n",
            "[21,   900] loss: 0.514\n",
            "[21,  1200] loss: 0.531\n",
            "[21,  1500] loss: 0.533\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 82.382 Testing Accuracy 76.2\n",
            "############################\n",
            "\n",
            "Epoch: 22\n",
            "[22,   300] loss: 0.498\n",
            "[22,   600] loss: 0.492\n",
            "[22,   900] loss: 0.517\n",
            "[22,  1200] loss: 0.503\n",
            "[22,  1500] loss: 0.501\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 83.522 Testing Accuracy 77.52\n",
            "############################\n",
            "\n",
            "Epoch: 23\n",
            "[23,   300] loss: 0.504\n",
            "[23,   600] loss: 0.498\n",
            "[23,   900] loss: 0.489\n",
            "[23,  1200] loss: 0.488\n",
            "[23,  1500] loss: 0.482\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 83.854 Testing Accuracy 77.61\n",
            "############################\n",
            "\n",
            "Epoch: 24\n",
            "[24,   300] loss: 0.481\n",
            "[24,   600] loss: 0.481\n",
            "[24,   900] loss: 0.478\n",
            "[24,  1200] loss: 0.478\n",
            "[24,  1500] loss: 0.487\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 84.034 Testing Accuracy 77.98\n",
            "############################\n",
            "\n",
            "Epoch: 25\n",
            "[25,   300] loss: 0.460\n",
            "[25,   600] loss: 0.484\n",
            "[25,   900] loss: 0.467\n",
            "[25,  1200] loss: 0.458\n",
            "[25,  1500] loss: 0.479\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 84.404 Testing Accuracy 77.81\n",
            "############################\n",
            "\n",
            "Epoch: 26\n",
            "[26,   300] loss: 0.463\n",
            "[26,   600] loss: 0.472\n",
            "[26,   900] loss: 0.443\n",
            "[26,  1200] loss: 0.456\n",
            "[26,  1500] loss: 0.454\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 85.016 Testing Accuracy 77.57\n",
            "############################\n",
            "\n",
            "Epoch: 27\n",
            "[27,   300] loss: 0.428\n",
            "[27,   600] loss: 0.449\n",
            "[27,   900] loss: 0.453\n",
            "[27,  1200] loss: 0.445\n",
            "[27,  1500] loss: 0.469\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 85.202 Testing Accuracy 78.38\n",
            "############################\n",
            "\n",
            "Epoch: 28\n",
            "[28,   300] loss: 0.427\n",
            "[28,   600] loss: 0.435\n",
            "[28,   900] loss: 0.445\n",
            "[28,  1200] loss: 0.450\n",
            "[28,  1500] loss: 0.449\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 85.802 Testing Accuracy 78.39\n",
            "############################\n",
            "\n",
            "Epoch: 29\n",
            "[29,   300] loss: 0.430\n",
            "[29,   600] loss: 0.424\n",
            "[29,   900] loss: 0.415\n",
            "[29,  1200] loss: 0.446\n",
            "[29,  1500] loss: 0.416\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 85.994 Testing Accuracy 79.19\n",
            "############################\n",
            "\n",
            "Epoch: 30\n",
            "[30,   300] loss: 0.418\n",
            "[30,   600] loss: 0.426\n",
            "[30,   900] loss: 0.426\n",
            "[30,  1200] loss: 0.408\n",
            "[30,  1500] loss: 0.431\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 86.344 Testing Accuracy 78.57\n",
            "############################\n",
            "\n",
            "Epoch: 31\n",
            "[31,   300] loss: 0.410\n",
            "[31,   600] loss: 0.396\n",
            "[31,   900] loss: 0.398\n",
            "[31,  1200] loss: 0.419\n",
            "[31,  1500] loss: 0.412\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 86.404 Testing Accuracy 78.83\n",
            "############################\n",
            "\n",
            "Epoch: 32\n",
            "[32,   300] loss: 0.387\n",
            "[32,   600] loss: 0.404\n",
            "[32,   900] loss: 0.404\n",
            "[32,  1200] loss: 0.412\n",
            "[32,  1500] loss: 0.402\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 87.034 Testing Accuracy 79.47\n",
            "############################\n",
            "\n",
            "Epoch: 33\n",
            "[33,   300] loss: 0.397\n",
            "[33,   600] loss: 0.393\n",
            "[33,   900] loss: 0.384\n",
            "[33,  1200] loss: 0.394\n",
            "[33,  1500] loss: 0.395\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 86.652 Testing Accuracy 79.09\n",
            "############################\n",
            "\n",
            "Epoch: 34\n",
            "[34,   300] loss: 0.375\n",
            "[34,   600] loss: 0.382\n",
            "[34,   900] loss: 0.388\n",
            "[34,  1200] loss: 0.391\n",
            "[34,  1500] loss: 0.383\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 87.362 Testing Accuracy 79.63\n",
            "############################\n",
            "\n",
            "Epoch: 35\n",
            "[35,   300] loss: 0.366\n",
            "[35,   600] loss: 0.382\n",
            "[35,   900] loss: 0.389\n",
            "[35,  1200] loss: 0.389\n",
            "[35,  1500] loss: 0.394\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 87.51 Testing Accuracy 80.19\n",
            "############################\n",
            "\n",
            "Epoch: 36\n",
            "[36,   300] loss: 0.383\n",
            "[36,   600] loss: 0.356\n",
            "[36,   900] loss: 0.384\n",
            "[36,  1200] loss: 0.366\n",
            "[36,  1500] loss: 0.381\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 87.738 Testing Accuracy 79.04\n",
            "############################\n",
            "\n",
            "Epoch: 37\n",
            "[37,   300] loss: 0.358\n",
            "[37,   600] loss: 0.366\n",
            "[37,   900] loss: 0.353\n",
            "[37,  1200] loss: 0.376\n",
            "[37,  1500] loss: 0.367\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 88.074 Testing Accuracy 80.45\n",
            "############################\n",
            "\n",
            "Epoch: 38\n",
            "[38,   300] loss: 0.355\n",
            "[38,   600] loss: 0.348\n",
            "[38,   900] loss: 0.358\n",
            "[38,  1200] loss: 0.377\n",
            "[38,  1500] loss: 0.356\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 88.098 Testing Accuracy 80.07\n",
            "############################\n",
            "\n",
            "Epoch: 39\n",
            "[39,   300] loss: 0.349\n",
            "[39,   600] loss: 0.338\n",
            "[39,   900] loss: 0.353\n",
            "[39,  1200] loss: 0.347\n",
            "[39,  1500] loss: 0.374\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 88.602 Testing Accuracy 80.5\n",
            "############################\n",
            "\n",
            "Epoch: 40\n",
            "[40,   300] loss: 0.349\n",
            "[40,   600] loss: 0.335\n",
            "[40,   900] loss: 0.347\n",
            "[40,  1200] loss: 0.359\n",
            "[40,  1500] loss: 0.347\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 88.786 Testing Accuracy 80.68\n",
            "############################\n",
            "\n",
            "Epoch: 41\n",
            "[41,   300] loss: 0.346\n",
            "[41,   600] loss: 0.336\n",
            "[41,   900] loss: 0.323\n",
            "[41,  1200] loss: 0.342\n",
            "[41,  1500] loss: 0.341\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 88.794 Testing Accuracy 80.29\n",
            "############################\n",
            "\n",
            "Epoch: 42\n",
            "[42,   300] loss: 0.335\n",
            "[42,   600] loss: 0.314\n",
            "[42,   900] loss: 0.336\n",
            "[42,  1200] loss: 0.350\n",
            "[42,  1500] loss: 0.347\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 88.928 Testing Accuracy 81.08\n",
            "############################\n",
            "\n",
            "Epoch: 43\n",
            "[43,   300] loss: 0.326\n",
            "[43,   600] loss: 0.330\n",
            "[43,   900] loss: 0.322\n",
            "[43,  1200] loss: 0.325\n",
            "[43,  1500] loss: 0.326\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 89.058 Testing Accuracy 81.01\n",
            "############################\n",
            "\n",
            "Epoch: 44\n",
            "[44,   300] loss: 0.303\n",
            "[44,   600] loss: 0.314\n",
            "[44,   900] loss: 0.322\n",
            "[44,  1200] loss: 0.332\n",
            "[44,  1500] loss: 0.343\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 89.572 Testing Accuracy 81.53\n",
            "############################\n",
            "\n",
            "Epoch: 45\n",
            "[45,   300] loss: 0.303\n",
            "[45,   600] loss: 0.322\n",
            "[45,   900] loss: 0.314\n",
            "[45,  1200] loss: 0.327\n",
            "[45,  1500] loss: 0.337\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 89.418 Testing Accuracy 80.33\n",
            "############################\n",
            "\n",
            "Epoch: 46\n",
            "[46,   300] loss: 0.300\n",
            "[46,   600] loss: 0.304\n",
            "[46,   900] loss: 0.301\n",
            "[46,  1200] loss: 0.314\n",
            "[46,  1500] loss: 0.311\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 89.592 Testing Accuracy 80.83\n",
            "############################\n",
            "\n",
            "Epoch: 47\n",
            "[47,   300] loss: 0.320\n",
            "[47,   600] loss: 0.300\n",
            "[47,   900] loss: 0.304\n",
            "[47,  1200] loss: 0.309\n",
            "[47,  1500] loss: 0.316\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 89.852 Testing Accuracy 81.09\n",
            "############################\n",
            "\n",
            "Epoch: 48\n",
            "[48,   300] loss: 0.295\n",
            "[48,   600] loss: 0.314\n",
            "[48,   900] loss: 0.297\n",
            "[48,  1200] loss: 0.307\n",
            "[48,  1500] loss: 0.305\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 89.72 Testing Accuracy 81.06\n",
            "############################\n",
            "\n",
            "Epoch: 49\n",
            "[49,   300] loss: 0.295\n",
            "[49,   600] loss: 0.293\n",
            "[49,   900] loss: 0.287\n",
            "[49,  1200] loss: 0.316\n",
            "[49,  1500] loss: 0.299\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 90.326 Testing Accuracy 81.4\n",
            "############################\n",
            "\n",
            "Epoch: 50\n",
            "[50,   300] loss: 0.279\n",
            "[50,   600] loss: 0.299\n",
            "[50,   900] loss: 0.284\n",
            "[50,  1200] loss: 0.304\n",
            "[50,  1500] loss: 0.291\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 90.364 Testing Accuracy 80.62\n",
            "############################\n",
            "\n",
            "Epoch: 51\n",
            "[51,   300] loss: 0.266\n",
            "[51,   600] loss: 0.289\n",
            "[51,   900] loss: 0.280\n",
            "[51,  1200] loss: 0.300\n",
            "[51,  1500] loss: 0.284\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 90.652 Testing Accuracy 82.38\n",
            "############################\n",
            "\n",
            "Epoch: 52\n",
            "[52,   300] loss: 0.292\n",
            "[52,   600] loss: 0.283\n",
            "[52,   900] loss: 0.280\n",
            "[52,  1200] loss: 0.278\n",
            "[52,  1500] loss: 0.275\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 90.366 Testing Accuracy 81.29\n",
            "############################\n",
            "\n",
            "Epoch: 53\n",
            "[53,   300] loss: 0.272\n",
            "[53,   600] loss: 0.285\n",
            "[53,   900] loss: 0.278\n",
            "[53,  1200] loss: 0.283\n",
            "[53,  1500] loss: 0.281\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 90.746 Testing Accuracy 82.0\n",
            "############################\n",
            "\n",
            "Epoch: 54\n",
            "[54,   300] loss: 0.259\n",
            "[54,   600] loss: 0.263\n",
            "[54,   900] loss: 0.285\n",
            "[54,  1200] loss: 0.282\n",
            "[54,  1500] loss: 0.275\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 90.964 Testing Accuracy 81.19\n",
            "############################\n",
            "\n",
            "Epoch: 55\n",
            "[55,   300] loss: 0.262\n",
            "[55,   600] loss: 0.264\n",
            "[55,   900] loss: 0.282\n",
            "[55,  1200] loss: 0.275\n",
            "[55,  1500] loss: 0.264\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 91.378 Testing Accuracy 81.91\n",
            "############################\n",
            "\n",
            "Epoch: 56\n",
            "[56,   300] loss: 0.271\n",
            "[56,   600] loss: 0.267\n",
            "[56,   900] loss: 0.270\n",
            "[56,  1200] loss: 0.266\n",
            "[56,  1500] loss: 0.267\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 91.624 Testing Accuracy 82.01\n",
            "############################\n",
            "\n",
            "Epoch: 57\n",
            "[57,   300] loss: 0.254\n",
            "[57,   600] loss: 0.256\n",
            "[57,   900] loss: 0.268\n",
            "[57,  1200] loss: 0.268\n",
            "[57,  1500] loss: 0.266\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 91.55 Testing Accuracy 81.62\n",
            "############################\n",
            "\n",
            "Epoch: 58\n",
            "[58,   300] loss: 0.245\n",
            "[58,   600] loss: 0.256\n",
            "[58,   900] loss: 0.253\n",
            "[58,  1200] loss: 0.263\n",
            "[58,  1500] loss: 0.269\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 91.284 Testing Accuracy 82.05\n",
            "############################\n",
            "\n",
            "Epoch: 59\n",
            "[59,   300] loss: 0.259\n",
            "[59,   600] loss: 0.249\n",
            "[59,   900] loss: 0.245\n",
            "[59,  1200] loss: 0.260\n",
            "[59,  1500] loss: 0.259\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 91.306 Testing Accuracy 82.02\n",
            "############################\n",
            "\n",
            "Epoch: 60\n",
            "[60,   300] loss: 0.252\n",
            "[60,   600] loss: 0.236\n",
            "[60,   900] loss: 0.244\n",
            "[60,  1200] loss: 0.260\n",
            "[60,  1500] loss: 0.260\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 91.396 Testing Accuracy 81.77\n",
            "############################\n",
            "\n",
            "Epoch: 61\n",
            "[61,   300] loss: 0.245\n",
            "[61,   600] loss: 0.243\n",
            "[61,   900] loss: 0.237\n",
            "[61,  1200] loss: 0.261\n",
            "[61,  1500] loss: 0.261\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 91.548 Testing Accuracy 82.01\n",
            "############################\n",
            "\n",
            "Epoch: 62\n",
            "[62,   300] loss: 0.226\n",
            "[62,   600] loss: 0.238\n",
            "[62,   900] loss: 0.259\n",
            "[62,  1200] loss: 0.243\n",
            "[62,  1500] loss: 0.249\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 91.886 Testing Accuracy 81.87\n",
            "############################\n",
            "\n",
            "Epoch: 63\n",
            "[63,   300] loss: 0.234\n",
            "[63,   600] loss: 0.242\n",
            "[63,   900] loss: 0.241\n",
            "[63,  1200] loss: 0.241\n",
            "[63,  1500] loss: 0.244\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 92.12 Testing Accuracy 82.2\n",
            "############################\n",
            "\n",
            "Epoch: 64\n",
            "[64,   300] loss: 0.223\n",
            "[64,   600] loss: 0.232\n",
            "[64,   900] loss: 0.245\n",
            "[64,  1200] loss: 0.242\n",
            "[64,  1500] loss: 0.243\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 92.222 Testing Accuracy 82.04\n",
            "############################\n",
            "\n",
            "Epoch: 65\n",
            "[65,   300] loss: 0.222\n",
            "[65,   600] loss: 0.239\n",
            "[65,   900] loss: 0.234\n",
            "[65,  1200] loss: 0.232\n",
            "[65,  1500] loss: 0.236\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 92.236 Testing Accuracy 81.89\n",
            "############################\n",
            "\n",
            "Epoch: 66\n",
            "[66,   300] loss: 0.242\n",
            "[66,   600] loss: 0.240\n",
            "[66,   900] loss: 0.218\n",
            "[66,  1200] loss: 0.221\n",
            "[66,  1500] loss: 0.229\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 92.36 Testing Accuracy 82.28\n",
            "############################\n",
            "\n",
            "Epoch: 67\n",
            "[67,   300] loss: 0.223\n",
            "[67,   600] loss: 0.220\n",
            "[67,   900] loss: 0.219\n",
            "[67,  1200] loss: 0.231\n",
            "[67,  1500] loss: 0.226\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 92.686 Testing Accuracy 81.68\n",
            "############################\n",
            "\n",
            "Epoch: 68\n",
            "[68,   300] loss: 0.219\n",
            "[68,   600] loss: 0.232\n",
            "[68,   900] loss: 0.219\n",
            "[68,  1200] loss: 0.216\n",
            "[68,  1500] loss: 0.221\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 92.714 Testing Accuracy 81.85\n",
            "############################\n",
            "\n",
            "Epoch: 69\n",
            "[69,   300] loss: 0.226\n",
            "[69,   600] loss: 0.220\n",
            "[69,   900] loss: 0.208\n",
            "[69,  1200] loss: 0.229\n",
            "[69,  1500] loss: 0.228\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 92.67 Testing Accuracy 82.19\n",
            "############################\n",
            "\n",
            "Epoch: 70\n",
            "[70,   300] loss: 0.229\n",
            "[70,   600] loss: 0.203\n",
            "[70,   900] loss: 0.212\n",
            "[70,  1200] loss: 0.229\n",
            "[70,  1500] loss: 0.219\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 92.86 Testing Accuracy 82.63\n",
            "############################\n",
            "\n",
            "Epoch: 71\n",
            "[71,   300] loss: 0.205\n",
            "[71,   600] loss: 0.217\n",
            "[71,   900] loss: 0.227\n",
            "[71,  1200] loss: 0.205\n",
            "[71,  1500] loss: 0.215\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 92.832 Testing Accuracy 82.45\n",
            "############################\n",
            "\n",
            "Epoch: 72\n",
            "[72,   300] loss: 0.205\n",
            "[72,   600] loss: 0.206\n",
            "[72,   900] loss: 0.210\n",
            "[72,  1200] loss: 0.211\n",
            "[72,  1500] loss: 0.224\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 92.892 Testing Accuracy 82.27\n",
            "############################\n",
            "\n",
            "Epoch: 73\n",
            "[73,   300] loss: 0.209\n",
            "[73,   600] loss: 0.204\n",
            "[73,   900] loss: 0.209\n",
            "[73,  1200] loss: 0.220\n",
            "[73,  1500] loss: 0.210\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 93.35 Testing Accuracy 82.88\n",
            "############################\n",
            "\n",
            "Epoch: 74\n",
            "[74,   300] loss: 0.199\n",
            "[74,   600] loss: 0.211\n",
            "[74,   900] loss: 0.208\n",
            "[74,  1200] loss: 0.208\n",
            "[74,  1500] loss: 0.210\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 93.228 Testing Accuracy 82.57\n",
            "############################\n",
            "\n",
            "Epoch: 75\n",
            "[75,   300] loss: 0.200\n",
            "[75,   600] loss: 0.206\n",
            "[75,   900] loss: 0.208\n",
            "[75,  1200] loss: 0.203\n",
            "[75,  1500] loss: 0.206\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 93.59 Testing Accuracy 82.88\n",
            "############################\n",
            "\n",
            "Epoch: 76\n",
            "[76,   300] loss: 0.186\n",
            "[76,   600] loss: 0.202\n",
            "[76,   900] loss: 0.193\n",
            "[76,  1200] loss: 0.201\n",
            "[76,  1500] loss: 0.205\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 93.35 Testing Accuracy 82.84\n",
            "############################\n",
            "\n",
            "Epoch: 77\n",
            "[77,   300] loss: 0.194\n",
            "[77,   600] loss: 0.191\n",
            "[77,   900] loss: 0.207\n",
            "[77,  1200] loss: 0.202\n",
            "[77,  1500] loss: 0.189\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 93.37 Testing Accuracy 82.12\n",
            "############################\n",
            "\n",
            "Epoch: 78\n",
            "[78,   300] loss: 0.188\n",
            "[78,   600] loss: 0.187\n",
            "[78,   900] loss: 0.190\n",
            "[78,  1200] loss: 0.194\n",
            "[78,  1500] loss: 0.195\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 93.65 Testing Accuracy 82.32\n",
            "############################\n",
            "\n",
            "Epoch: 79\n",
            "[79,   300] loss: 0.175\n",
            "[79,   600] loss: 0.180\n",
            "[79,   900] loss: 0.209\n",
            "[79,  1200] loss: 0.197\n",
            "[79,  1500] loss: 0.194\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 93.768 Testing Accuracy 82.51\n",
            "############################\n",
            "\n",
            "Epoch: 80\n",
            "[80,   300] loss: 0.184\n",
            "[80,   600] loss: 0.194\n",
            "[80,   900] loss: 0.178\n",
            "[80,  1200] loss: 0.190\n",
            "[80,  1500] loss: 0.198\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 93.666 Testing Accuracy 82.55\n",
            "############################\n",
            "\n",
            "Epoch: 81\n",
            "[81,   300] loss: 0.193\n",
            "[81,   600] loss: 0.183\n",
            "[81,   900] loss: 0.202\n",
            "[81,  1200] loss: 0.182\n",
            "[81,  1500] loss: 0.196\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 93.676 Testing Accuracy 82.6\n",
            "############################\n",
            "\n",
            "Epoch: 82\n",
            "[82,   300] loss: 0.190\n",
            "[82,   600] loss: 0.184\n",
            "[82,   900] loss: 0.190\n",
            "[82,  1200] loss: 0.182\n",
            "[82,  1500] loss: 0.179\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 93.518 Testing Accuracy 82.7\n",
            "############################\n",
            "\n",
            "Epoch: 83\n",
            "[83,   300] loss: 0.167\n",
            "[83,   600] loss: 0.180\n",
            "[83,   900] loss: 0.184\n",
            "[83,  1200] loss: 0.191\n",
            "[83,  1500] loss: 0.184\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 93.972 Testing Accuracy 83.27\n",
            "############################\n",
            "\n",
            "Epoch: 84\n",
            "[84,   300] loss: 0.188\n",
            "[84,   600] loss: 0.187\n",
            "[84,   900] loss: 0.187\n",
            "[84,  1200] loss: 0.183\n",
            "[84,  1500] loss: 0.186\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 93.822 Testing Accuracy 82.66\n",
            "############################\n",
            "\n",
            "Epoch: 85\n",
            "[85,   300] loss: 0.175\n",
            "[85,   600] loss: 0.179\n",
            "[85,   900] loss: 0.195\n",
            "[85,  1200] loss: 0.188\n",
            "[85,  1500] loss: 0.182\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 94.244 Testing Accuracy 83.34\n",
            "############################\n",
            "\n",
            "Epoch: 86\n",
            "[86,   300] loss: 0.166\n",
            "[86,   600] loss: 0.178\n",
            "[86,   900] loss: 0.182\n",
            "[86,  1200] loss: 0.173\n",
            "[86,  1500] loss: 0.184\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 94.41 Testing Accuracy 83.06\n",
            "############################\n",
            "\n",
            "Epoch: 87\n",
            "[87,   300] loss: 0.175\n",
            "[87,   600] loss: 0.165\n",
            "[87,   900] loss: 0.168\n",
            "[87,  1200] loss: 0.186\n",
            "[87,  1500] loss: 0.178\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 94.14 Testing Accuracy 82.85\n",
            "############################\n",
            "\n",
            "Epoch: 88\n",
            "[88,   300] loss: 0.158\n",
            "[88,   600] loss: 0.161\n",
            "[88,   900] loss: 0.172\n",
            "[88,  1200] loss: 0.170\n",
            "[88,  1500] loss: 0.172\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 94.394 Testing Accuracy 82.62\n",
            "############################\n",
            "\n",
            "Epoch: 89\n",
            "[89,   300] loss: 0.159\n",
            "[89,   600] loss: 0.161\n",
            "[89,   900] loss: 0.153\n",
            "[89,  1200] loss: 0.175\n",
            "[89,  1500] loss: 0.174\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 94.254 Testing Accuracy 83.42\n",
            "############################\n",
            "\n",
            "Epoch: 90\n",
            "[90,   300] loss: 0.163\n",
            "[90,   600] loss: 0.174\n",
            "[90,   900] loss: 0.167\n",
            "[90,  1200] loss: 0.169\n",
            "[90,  1500] loss: 0.175\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 94.568 Testing Accuracy 82.8\n",
            "############################\n",
            "\n",
            "Epoch: 91\n",
            "[91,   300] loss: 0.152\n",
            "[91,   600] loss: 0.158\n",
            "[91,   900] loss: 0.172\n",
            "[91,  1200] loss: 0.151\n",
            "[91,  1500] loss: 0.165\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 94.688 Testing Accuracy 83.25\n",
            "############################\n",
            "\n",
            "Epoch: 92\n",
            "[92,   300] loss: 0.151\n",
            "[92,   600] loss: 0.157\n",
            "[92,   900] loss: 0.163\n",
            "[92,  1200] loss: 0.154\n",
            "[92,  1500] loss: 0.171\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 94.676 Testing Accuracy 82.78\n",
            "############################\n",
            "\n",
            "Epoch: 93\n",
            "[93,   300] loss: 0.159\n",
            "[93,   600] loss: 0.158\n",
            "[93,   900] loss: 0.168\n",
            "[93,  1200] loss: 0.163\n",
            "[93,  1500] loss: 0.160\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 94.538 Testing Accuracy 82.6\n",
            "############################\n",
            "\n",
            "Epoch: 94\n",
            "[94,   300] loss: 0.163\n",
            "[94,   600] loss: 0.162\n",
            "[94,   900] loss: 0.153\n",
            "[94,  1200] loss: 0.164\n",
            "[94,  1500] loss: 0.159\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 94.872 Testing Accuracy 82.7\n",
            "############################\n",
            "\n",
            "Epoch: 95\n",
            "[95,   300] loss: 0.142\n",
            "[95,   600] loss: 0.158\n",
            "[95,   900] loss: 0.163\n",
            "[95,  1200] loss: 0.169\n",
            "[95,  1500] loss: 0.176\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 94.676 Testing Accuracy 83.48\n",
            "############################\n",
            "\n",
            "Epoch: 96\n",
            "[96,   300] loss: 0.150\n",
            "[96,   600] loss: 0.149\n",
            "[96,   900] loss: 0.159\n",
            "[96,  1200] loss: 0.166\n",
            "[96,  1500] loss: 0.151\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 94.676 Testing Accuracy 83.74\n",
            "############################\n",
            "\n",
            "Epoch: 97\n",
            "[97,   300] loss: 0.149\n",
            "[97,   600] loss: 0.145\n",
            "[97,   900] loss: 0.150\n",
            "[97,  1200] loss: 0.145\n",
            "[97,  1500] loss: 0.163\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 95.016 Testing Accuracy 83.3\n",
            "############################\n",
            "\n",
            "Epoch: 98\n",
            "[98,   300] loss: 0.145\n",
            "[98,   600] loss: 0.150\n",
            "[98,   900] loss: 0.150\n",
            "[98,  1200] loss: 0.150\n",
            "[98,  1500] loss: 0.159\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 94.992 Testing Accuracy 83.06\n",
            "############################\n",
            "\n",
            "Epoch: 99\n",
            "[99,   300] loss: 0.145\n",
            "[99,   600] loss: 0.153\n",
            "[99,   900] loss: 0.149\n",
            "[99,  1200] loss: 0.154\n",
            "[99,  1500] loss: 0.160\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 94.908 Testing Accuracy 82.72\n",
            "############################\n",
            "\n",
            "Epoch: 100\n",
            "[100,   300] loss: 0.136\n",
            "[100,   600] loss: 0.150\n",
            "[100,   900] loss: 0.154\n",
            "[100,  1200] loss: 0.141\n",
            "[100,  1500] loss: 0.157\n",
            "EPOCH OVER\n",
            "############################\n",
            "Training Accuracy: 95.16 Testing Accuracy 83.05\n",
            "############################\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWRTi5XKCjNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKfQBsSKdle4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = '/content/gdrive/My Drive/Pytorch_Practice/CIFAR-10_Model-1.pt'\n",
        "torch.save(net,PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC3hyVNIeyv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_2 = torch.load(PATH)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}